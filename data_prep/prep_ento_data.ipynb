{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b3cb1d6",
   "metadata": {},
   "source": [
    "# Blackfly Habitat Suitability Modelling Project: Data preparation\n",
    "This script prepares entomological surveillance data from the Nigerian FMoH and National Oncho Elimination Program, collected by various implementing partners and research partners and prepares to be inputs into the suitability model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32825551",
   "metadata": {},
   "source": [
    "## Inputs:\n",
    "+ The Carter Center (TCC)- collected FMoH entomological surveillance data \n",
    "+ Dr. Adeleke's research data\n",
    "+ CBM-collected FMoH entomological surveillance data\n",
    "+ Dr. Louise Kelly-Hope's historical literature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a430f90d",
   "metadata": {},
   "source": [
    "## Outputs:\n",
    "+ 1 csv containing:\n",
    "    + Location (latitude, longitude)\n",
    "    + Binary presence/absence (1/0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cfdd1c",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab779522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import logging\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edb3094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import click\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e13f41",
   "metadata": {},
   "source": [
    "what's happening here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d02378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_level(level):\n",
    "    if level == 'INFO':\n",
    "        return logging.INFO\n",
    "    elif level == 'WARNING':\n",
    "        return logging.WARNING\n",
    "    elif level == 'ERROR':\n",
    "        return logging.ERROR\n",
    "    else:\n",
    "        logging.critical(f'Logging level {level} Unsupported.')\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bd398e",
   "metadata": {},
   "source": [
    "# Define script args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f425d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADULT_FLY_PRESENCE = 'Presence of Adult Fly'\n",
    "BOOK_KEEPING = ['Row Number', 'Filename']\n",
    "ACCEPTED_COLUMNS = BOOK_KEEPING + ['Latitude', 'Longitude', ADULT_FLY_PRESENCE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42155384",
   "metadata": {},
   "source": [
    "# Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@click.command()\n",
    "@click.option('--in_dir', type=click.Path(),\n",
    "              help='Directory containing field data CSVs to clean.')\n",
    "@click.option('--out_dir', default='.', type=click.Path(),\n",
    "              help='Directory to save cleaned field data. (Default: Current Directory)')\n",
    "@click.option('--out_file_prefix', default='usf_pipeline', type=str,\n",
    "              help='Prefix of output files (Default: usf_pipeline)')\n",
    "@click.option('--log_level', default='INFO', type=str,\n",
    "              help='INFO, WARNING, ERROR (Default: INFO)')\n",
    "def clean_data(in_dir, out_dir, out_file_prefix, log_level):\n",
    "    logging.basicConfig(level=get_log_level(log_level))\n",
    "    # Create a list to store all of the accepted rows\n",
    "    accepted = []\n",
    "    # Create a dictionary to store the rejected columns from each format\n",
    "    rejected = {'FORMAT_ONE': [], 'FORMAT_TWO': [], 'FORMAT_THREE': [], 'FORMAT_FOUR': []}\n",
    "    for file in glob(os.path.join(in_dir, '*.csv')):\n",
    "        logging.info(f'Processing {file}')\n",
    "        df = pd.read_csv(file, dtype=str)\n",
    "        # Remove any white space from beginning or end of column names\n",
    "        df = df.rename(columns={col: col.strip() for col in df.columns})\n",
    "        # Save the filename as a column in the dataframe for book keeping\n",
    "        df['Filename'] = os.path.basename(file)\n",
    "        # Assign a 'Row Number' column for book keeping\n",
    "        df['Row Number'] = df.index + 1\n",
    "        # If all of the columns for a known format are present, process accordingly\n",
    "        if all([col in df.columns for col in FORMAT_ONE_COLS]):\n",
    "            accept, reject = clean_known_format_one(df)\n",
    "            rejected['FORMAT_ONE'].append(reject)\n",
    "        elif all([col in df.columns for col in FORMAT_TWO_COLS]):\n",
    "            accept, reject = clean_known_format_two(df)\n",
    "            rejected['FORMAT_TWO'].append(reject)\n",
    "        elif all([col in df.columns for col in FORMAT_THREE_COLS]):\n",
    "            accept, reject = clean_known_format_three(df)\n",
    "            rejected['FORMAT_THREE'].append(reject)\n",
    "        elif len([col for col in df.columns if col.startswith('n_flies_total_')]) == NUM_N_COLS:\n",
    "            accept, reject = clean_known_format_four(df)\n",
    "            rejected['FORMAT_FOUR'].append(reject)\n",
    "        else:\n",
    "            logging.warning(f'Unknown Format: {file}')\n",
    "            continue\n",
    "        accepted.append(accept[ACCEPTED_COLUMNS])\n",
    "        if len(df) != len(accept) + len(reject):\n",
    "            logging.critical(f'Number of accepted and rejected rows do not add to total rows: {file}')\n",
    "            sys.exit()\n",
    "    # if there are accepted dataframes\n",
    "    if accepted:\n",
    "        # Turn list of dataframes into single dataframe\n",
    "        accepted_df = pd.concat(accepted)\n",
    "        # Save dataframe to CSV file\n",
    "        accepted_df.to_csv(os.path.join(out_dir, out_file_prefix + '_accepted.csv'), index=False)\n",
    "    # For each dataframe of rejected rows\n",
    "    for known_format, rejected_dfs in rejected.items():\n",
    "        if rejected_dfs:\n",
    "            reject_csv_name = out_file_prefix + '_' + known_format.lower() + '_rejected.csv'\n",
    "            reject_path = os.path.join(out_dir, reject_csv_name)\n",
    "            rejected_df = pd.concat(rejected_dfs)\n",
    "            if not rejected_df.empty:\n",
    "                rejected_df.to_csv(reject_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e34ede",
   "metadata": {},
   "source": [
    "# Geographic validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd26110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_geo(series):\n",
    "    \"\"\"check if value has greater that three digits after the decima\n",
    "       check that value is not a range (e.g. 5.6372 - 5.64652)\n",
    "    \n",
    "    Args:\n",
    "        series: Pandas Series to check for valid geodetic values\n",
    "    \n",
    "    Returns:\n",
    "        list of True/False values with True where geodetic values are valid\n",
    "    \"\"\"\n",
    "    # Regular Expression which matches a digit, then a space (zero or more),\n",
    "    # a dash, then a space (zero or more), then a digit.\n",
    "    range_regex = r'\\d\\s*-\\s*\\d'\n",
    "    return series.str.split('.').apply(lambda x: len(x[-1]) > 3) &\\\n",
    "           ~series.str.contains(range_regex, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4742af9a",
   "metadata": {},
   "source": [
    "# Defining csv Format 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a128b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNOWN FORMAT 1. When CSV contains these column names we know how to process it.\n",
    "CATCH_LAT = 'Latitude of catching point'\n",
    "CATCH_LON = 'Longitude of catching point'\n",
    "VILLAGE_LAT = 'Latitude of the village (if exist)'\n",
    "VILLAGE_LON = 'Longitude of the village (if exist)'\n",
    "ADULT_FLY = 'Presence of adult flies/Yes or No'\n",
    "FORMAT_ONE_COLS = [CATCH_LAT, CATCH_LON, VILLAGE_LAT, VILLAGE_LON, ADULT_FLY]\n",
    "def clean_known_format_one(df):\n",
    "    # List of True only where either VILLAGE_LAT or VILLAGE_LON is blank\n",
    "    village_nulls = df[VILLAGE_LAT].isnull() | df[VILLAGE_LON].isnull()\n",
    "    # List of True only where either CATCH_LAT or CATCH_LON is blank\n",
    "    catch_nulls = df[CATCH_LAT].isnull() | df[CATCH_LON].isnull()\n",
    "    # Save rows with no valid lat/lons to reject dataframe\n",
    "    reject = df[(village_nulls & catch_nulls)]\n",
    "    # Remove rows where at least one of village lat/lon or catch lat/lon is present\n",
    "    df = df[(~village_nulls | ~catch_nulls)]\n",
    "    # New 'Latitude' column with CATCH_LAT if filled in, otherwise use VILLAGE_LAT\n",
    "    df = df.assign(Latitude=df[CATCH_LAT].combine_first(df[VILLAGE_LAT]))\n",
    "    # New 'Longitude' column with CATCH_LAT if filled in, otherwise use VILLAGE_LON\n",
    "    df = df.assign(Longitude=df[CATCH_LON].combine_first(df[VILLAGE_LON]))\n",
    "    # List of True where geodetic values are valid\n",
    "    valid_geos = is_valid_geo(df['Latitude']) & is_valid_geo(df['Longitude'])\n",
    "    # Save rows with invalid geodetic values, concatenated to previous rejections\n",
    "    reject = pd.concat([reject, df[~valid_geos]])\n",
    "    # Remove rows with invalid geodetic values\n",
    "    df = df[valid_geos]\n",
    "    # Set ADULT_FLY_PRESENCE to ADULT_FLY\n",
    "    df[ADULT_FLY_PRESENCE] = df[ADULT_FLY]\n",
    "    # Reformat ADULT_FLY_PRESENCE column values to have first letter capatilized\n",
    "    df[ADULT_FLY_PRESENCE] = df[ADULT_FLY_PRESENCE].str.title()\n",
    "    # Fill NaN with Not Available\n",
    "    df[ADULT_FLY_PRESENCE] = df[ADULT_FLY_PRESENCE].fillna('NA')\n",
    "    return df, reject[BOOK_KEEPING + FORMAT_ONE_COLS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a5d214",
   "metadata": {},
   "source": [
    "# Define Adeleke-specific fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfc204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVIDENCE_OF_ADULT = 'r_EvidenceOfAdult'\n",
    "GPS_RIVER_BASIN = 'r_GPS_river_basin'\n",
    "FORMAT_TWO_COLS = [EVIDENCE_OF_ADULT, GPS_RIVER_BASIN]\n",
    "# KNOWN FORMAT 2. When CSV contains these column names we know how to process it.\n",
    "def clean_known_format_two(df):\n",
    "    # Replace any '---' value in the dataframe with not a number\n",
    "    df = df.replace('---', np.nan)\n",
    "    # Expand the 'r_GPS_river_basin' column into four new_columns\n",
    "    new_columns = ['Latitude', 'Longitude', GPS_RIVER_BASIN + '_3', GPS_RIVER_BASIN + '_4']\n",
    "    df[new_columns] = df[GPS_RIVER_BASIN].str.split(' ', expand=True)\n",
    "    # List of True only where either Latitude or Longitude is blank\n",
    "    geo_nulls = df['Latitude'].isnull() | df['Longitude'].isnull()\n",
    "    # Save rows with nulls in reject dataframe\n",
    "    reject = df[geo_nulls]\n",
    "    # Remove rows where village or catch lat/lon have nulls\n",
    "    df = df[~geo_nulls]\n",
    "    # List of True where geodetic values are valid\n",
    "    valid_geos = is_valid_geo(df['Latitude']) & is_valid_geo(df['Longitude'])\n",
    "    # Save rows with invalid geodetic values concatenated to previous rejections\n",
    "    reject = pd.concat([reject, df[~valid_geos]])\n",
    "    # Remove rows with invalid geodetic values\n",
    "    df = df[valid_geos]\n",
    "    # Set ADULT_FLY_PRESENCE to EVIDENCE_OF_ADULT\n",
    "    df[ADULT_FLY_PRESENCE] = df[EVIDENCE_OF_ADULT]\n",
    "    # Reformat ADULT_FLY_PRESENCE column values to have frst letter capatilized\n",
    "    df[ADULT_FLY_PRESENCE] = df[ADULT_FLY_PRESENCE].str.title()\n",
    "    # Fill NaN with Not Available\n",
    "    df[ADULT_FLY_PRESENCE] = df[ADULT_FLY_PRESENCE].fillna('NA')\n",
    "    return df, reject[BOOK_KEEPING + FORMAT_TWO_COLS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c56d82f",
   "metadata": {},
   "source": [
    "# Formatting 3 specific cols (from which dataset?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce03317",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMAT_THREE_COLS = ['lat', 'lon', 'fly_stage']\n",
    "def clean_known_format_three(df):\n",
    "    df = df.replace('NA', np.nan)\n",
    "    # Set Latitude and Longitude columns\n",
    "    df[['Latitude', 'Longitude']] = df[['lat', 'lon']]\n",
    "    # List of True only where either Latitude or Longitude is blank\n",
    "    geo_nulls = df['Latitude'].isnull() | df['Longitude'].isnull()\n",
    "    # Save rows with nulls in reject dataframe\n",
    "    reject = df[geo_nulls]\n",
    "    # Remove rows where village or catch lat/lon have nulls\n",
    "    df = df[~geo_nulls]\n",
    "    # List of True where geodetic values are valid\n",
    "    valid_geos = is_valid_geo(df['Latitude']) & is_valid_geo(df['Longitude'])\n",
    "    # Save rows with invalid geodetic values concatenated to previous rejections\n",
    "    reject = pd.concat([reject, df[~valid_geos]])\n",
    "    # Remove rows with invalid geodetic values\n",
    "    df = df[valid_geos]\n",
    "    # List of True only where adult is in fly_stage, ignore case sensitivity\n",
    "    adults = df.fly_stage.str.contains('adult', case=False).fillna(False)\n",
    "    # Copy fly_stage column to ADULT_FLY_PRESENCE\n",
    "    df[ADULT_FLY_PRESENCE] = df['fly_stage']\n",
    "    # Replace NaN with Not Available\n",
    "    df[ADULT_FLY_PRESENCE] = df[ADULT_FLY_PRESENCE].fillna('NA')\n",
    "    # Everywhere there's adults, fill in yes\n",
    "    df.loc[adults, ADULT_FLY_PRESENCE] = 'Yes'\n",
    "    # Everywhere there's not adults, fill in No\n",
    "    df.loc[~adults, ADULT_FLY_PRESENCE] = 'No'\n",
    "    return df, reject[BOOK_KEEPING + FORMAT_THREE_COLS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9c408a",
   "metadata": {},
   "source": [
    "# Format 4 specific cols (from which dataset?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ded3f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_N_COLS = 12\n",
    "FORMAT_FOUR_COLS = ['Latitude', 'Longitude']\n",
    "def clean_known_format_four(df):\n",
    "    # List of True only where either Latitude or Longitude is blank\n",
    "    geo_nulls = df['Latitude'].isnull() | df['Longitude'].isnull()\n",
    "    # Save rows with nulls in reject dataframe\n",
    "    reject = df[geo_nulls]\n",
    "    # Remove rows where village or catch lat/lon have nulls\n",
    "    df = df[~geo_nulls]\n",
    "    # List of True where geodetic values are valid\n",
    "    valid_geos = is_valid_geo(df['Latitude']) & is_valid_geo(df['Longitude'])\n",
    "    # Save rows with invalid geodetic values concatenated to previous rejections\n",
    "    reject = pd.concat([reject, df[~valid_geos]])\n",
    "    # Remove rows with invalid geodetic values\n",
    "    df = df[valid_geos]\n",
    "    # Get a list of every column that starts with n_flies_total_\n",
    "    n_flies_total_cols = [col for col in df.columns if col.startswith('n_flies_total_')]\n",
    "    # Sum all the n_flies_total_ rows\n",
    "    n_flies_total_col_sums = df[n_flies_total_cols].fillna(0).astype(int).sum(axis=1)\n",
    "    # Initialize new column ADULT_FLY_PRESENCE to 'No'\n",
    "    df[ADULT_FLY_PRESENCE] = 'No'\n",
    "    # Set 'Yes' where 1 or more flies counted.\n",
    "    df.loc[n_flies_total_col_sums > 0, ADULT_FLY_PRESENCE] = 'Yes'\n",
    "    return df, reject[BOOK_KEEPING + FORMAT_FOUR_COLS + n_flies_total_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a4936",
   "metadata": {},
   "source": [
    "# Call cleaning functions - run script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c13b986",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    clean_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
